{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "nombre = 'Vidal'\n",
    "filename = 'd:/Facultad/Tesis/Twitter/201910-'+nombre+'.txt'\n",
    "\n",
    "def take_url(json_data):\n",
    "    try:\n",
    "        url = json_data['urls'][0]['expanded_url']\n",
    "    except:\n",
    "        url = ''\n",
    "    return url\n",
    "\n",
    "def replace(x):\n",
    "    x = str(x)\n",
    "    x = x.replace('”', '\"')\n",
    "    x = x.replace('“', '\"')\n",
    "    x = x.replace('”', '\"')\n",
    "    x = x.replace('\\x93', '\"')\n",
    "    x = x.replace('\\x94', '\"')\n",
    "    \n",
    "\n",
    "def extract_quotes(x):\n",
    "    return re.findall('\"([^\"]*)\"', x)\n",
    "\n",
    "def salvando_tweets(filename):\n",
    "    dias = []\n",
    "    frases = []\n",
    "    urls = []\n",
    "    verified = []\n",
    "    with open(filename, 'r', encoding = \"utf8\") as fp:\n",
    "        for i, line in enumerate(fp):\n",
    "            # Para cada linea lee el json y extrae la fecha\n",
    "            json_data = json.loads(line)\n",
    "            url = take_url(json_data)\n",
    "            tweet = json_data['text']\n",
    "            url = json_data['urls']\n",
    "            extra = json_data\n",
    "\n",
    "\n",
    "\n",
    "            if tweet[0:2] != 'RT':\n",
    "                user = json_data['user']\n",
    "                frases.append(tweet)\n",
    "                dias.append(json_data['created_at'])\n",
    "\n",
    "                try:\n",
    "                    verified.append(user['verified'])\n",
    "                except:\n",
    "                    verified.append(False)\n",
    "\n",
    "                try:\n",
    "                    urls.append(url[0]['url'])\n",
    "                except:\n",
    "                    urls.append(0)\n",
    "\n",
    "        return frases, dias, urls, verified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def borrar_url(tweet, url):\n",
    "    if urls != 0:\n",
    "        try:\n",
    "            t = tweet.replace(str(url), \"\")     \n",
    "        except:\n",
    "            t = tweet\n",
    "    else:\n",
    "        t = tweet\n",
    "    return t\n",
    "\n",
    "frases, dias, urls, verified = salvando_tweets(filename)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'Tweets': frases, 'Fecha': dias, 'urls': urls, 'verified': verified})\n",
    "df['Tweets_sin_url'] = df.apply(lambda row: borrar_url(row['Tweets'], row['urls']), axis = 1)\n",
    "df.to_csv(\"Tweets_\"+nombre+\"_oct.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
