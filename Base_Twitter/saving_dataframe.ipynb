{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "nombre = 'Macri'\n",
    "mes = '08'\n",
    "filename = 'c:/Facultad/Tesis/Twitter/2019'+mes+'-'+nombre+'.txt'\n",
    "medios_oficiales = ['Clarín', 'La Nación', 'El Litoral', 'Página|12', 'Bariloche Digital', 'Diario El Ciudadano', 'Radio Mitre', 'infobae', 'TN - Todo Noticias', 'Ámbito Financiero']\n",
    "medios_oficiales_screnn = ['clarincom', 'lanacion', 'ellitoral', 'pagina12', 'barilochedigital', 'elciudadanoweb', 'radiomitre', 'infobae', 'todonoticias', 'Ambitocom']\n",
    "medios_oficiales_screnn_2 = ['ellitoral', 'barilochedigital', 'pagina12', 'elciudadanodiario', 'elsigloweb', 'diarionorte', 'diariotextual', 'opisantacruz', 'eldiadelaplata', 'elciudadanoweb', 'chubutparatodos', 'tunoticia', 'diarionoticias', 'lagacetasalta', 'radiomitre', 'elzonda', 'jujuyaldia', 'santacruzalmomento', 'eldoce', 'tncorrientes', 'ultimahora', 'elpregon', 'misionesonline', 'informatesalta', 'losandes', 'laprensa', 'losprimerostv', 'diariouno', 'corrienteshoy', 'elesquiu', 'lamañanaformosa', 'app', 'infobae', 'lagaceta', 'lanacion', 'tn', 'clarin', 'laredlarioja', 'infomerlo', 'm24digital', 'elliberal', 'diariamente', 'chacodiapordia', 'informedigital', 'laprensafederal', 'elindependiente', 'vocescriticas', 'opinionciudadana', 'lamañanacordoba', 'elancasti', 'eltiemposanjuan', 'primeraedicion', 'telam', 'ambito', 'elcomodorense', 'surenio', 'lavoz']\n",
    "def take_url(json_data):\n",
    "    try:\n",
    "        url = json_data['urls'][0]['expanded_url']\n",
    "    except:\n",
    "        url = ''\n",
    "    return url\n",
    "\n",
    "def replace(x):\n",
    "    x = str(x)\n",
    "    x = x.replace('”', '\"')\n",
    "    x = x.replace('“', '\"')\n",
    "    x = x.replace('”', '\"')\n",
    "    x = x.replace('\\x93', '\"')\n",
    "    x = x.replace('\\x94', '\"')\n",
    "    \n",
    "\n",
    "def extract_quotes(x):\n",
    "    return re.findall('\"([^\"]*)\"', x)\n",
    "\n",
    "def salvando_tweets(filename):\n",
    "    dias = []\n",
    "    frases = []\n",
    "    urls = []\n",
    "    url_reales = []\n",
    "    verified = []\n",
    "    medios = []\n",
    "    with open(filename, 'r', encoding = \"utf8\") as fp:\n",
    "        for i, line in enumerate(fp):\n",
    "            # Para cada linea lee el json y extrae la fecha\n",
    "            json_data = json.loads(line)\n",
    "            url_real = take_url(json_data)\n",
    "            tweet = json_data['text']\n",
    "            url = json_data['urls']\n",
    "            extra = json_data\n",
    "\n",
    "\n",
    "\n",
    "            if tweet[0:2] != 'RT':\n",
    "                user = json_data['user']\n",
    "                frases.append(tweet)\n",
    "                dias.append(json_data['created_at'])\n",
    "                \n",
    "                try:\n",
    "                    verified.append(user['verified'])\n",
    "                except:\n",
    "                    verified.append(False)\n",
    "\n",
    "                try:\n",
    "                    urls.append(url[0]['url'])\n",
    "                    url_reales.append(url_real)\n",
    "                except:\n",
    "                    urls.append(0)\n",
    "                    url_reales.append(0)\n",
    "\n",
    "\n",
    "                try:\n",
    "                    if user['name'] in medios_oficiales or user['screename'] in medios_oficiales_screnn or user['screename'] in medios_oficiales_screnn_2 :\n",
    "                        medios.append(True)\n",
    "                    else:\n",
    "                        medios.append(False)\n",
    "                except:\n",
    "                    medios.append(False)\n",
    "\n",
    "        return frases, dias, urls, url_reales,medios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def borrar_url(tweet, url):\n",
    "    if urls != 0:\n",
    "        try:\n",
    "            t = tweet.replace(str(url), \"\")     \n",
    "        except:\n",
    "            t = tweet\n",
    "    else:\n",
    "        t = tweet\n",
    "    return t\n",
    "\n",
    "frases, dias, urls, url_reales, medios = salvando_tweets(filename)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'Tweets': frases, 'Fecha': dias, 'urls': urls, 'urls_reales': url_reales, 'medios': medios})\n",
    "df['Tweets_sin_url'] = df.apply(lambda row: borrar_url(row['Tweets'], row['urls']), axis = 1)\n",
    "df.to_csv(\"Tweets_\"+nombre+\"_oct.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
